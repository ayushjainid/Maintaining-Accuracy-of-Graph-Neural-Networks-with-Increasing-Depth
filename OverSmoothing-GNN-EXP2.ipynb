{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F1op-CbyLuN4",
    "outputId": "1c8dbf0e-5901-44be-fa43-bd2bc4b2e32f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.2\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Install required packages.\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.nn import Linear\n",
    "import statistics\n",
    "import torch.nn.functional as F\n",
    "\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)\n",
    "\n",
    "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
    "\n",
    "# # Helper function for visualization.\n",
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.manifold import TSNE\n",
    "\n",
    "# def visualize(h, color):\n",
    "#     z = TSNE(n_components=2).fit_transform(h.detach().cpu().numpy())\n",
    "\n",
    "#     plt.figure(figsize=(10,10))\n",
    "#     plt.xticks([])\n",
    "#     plt.yticks([])\n",
    "\n",
    "#     plt.scatter(z[:, 0], z[:, 1], s=70, c=color, cmap=\"Set2\")\n",
    "#     plt.show()\n",
    "\n",
    "# Helper function for visualization.\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualization function for NX graph or PyTorch tensor\n",
    "def visualize(h, color, epoch=None, loss=None, accuracy=None):\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    if torch.is_tensor(h):\n",
    "        h = h.detach().cpu().numpy()\n",
    "        plt.scatter(h[:, 0], h[:, 1], s=140, c=color, cmap=\"Set2\")\n",
    "        if epoch is not None and loss is not None and accuracy['train'] is not None and accuracy['val'] is not None:\n",
    "            plt.xlabel((f'Epoch: {epoch}, Loss: {loss.item():.4f} \\n'\n",
    "                       f'Training Accuracy: {accuracy[\"train\"]*100:.2f}% \\n'\n",
    "                       f' Validation Accuracy: {accuracy[\"val\"]*100:.2f}%'),\n",
    "                       fontsize=16)\n",
    "    else:\n",
    "        nx.draw_networkx(G, pos=nx.spring_layout(G, seed=42), with_labels=False,\n",
    "                         node_color=color, cmap=\"Set2\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dszt2RUHE7lW"
   },
   "source": [
    "# Graph Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "imGrKO5YH11-",
    "outputId": "2a64e675-158c-4519-ab28-1923c4ab830a"
   },
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid, Reddit, Flickr, KarateClub, TUDataset, FacebookPagePage\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "\n",
    "dataset = Planetoid(root='data/Planetoid', name='Cora', transform=NormalizeFeatures())\n",
    "#dataset = Reddit(root='data/Reddit')\n",
    "#dataset = Flickr(root='data/Flickr')\n",
    "#dataset = FacebookPagePage(root='data/FacebookPagePage')\n",
    "#dataset = KarateClub()\n",
    "\n",
    "print()\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('======================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "data = dataset[0]  # Get the first graph object.\n",
    "\n",
    "print()\n",
    "print(data)\n",
    "print('===========================================================================================================')\n",
    "\n",
    "# Gather some statistics about the graph.\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Number of training nodes: {data.train_mask.sum()}')\n",
    "print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\n",
    "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Has self-loops: {data.has_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity_finder(node1, node2):\n",
    "    input1 = node1\n",
    "    input2 = node2\n",
    "    cos_sim = torch.nn.CosineSimilarity(dim=0)\n",
    "    #print(sim)\n",
    "    sim = cos_sim(node1, node2)\n",
    "    #print(sim)\n",
    "    max_val = torch.max(sim)\n",
    "    min_val = torch.min(sim)\n",
    "    return sim.item(), max_val, min_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_percentage(sim_list):\n",
    "#     cnt = 0\n",
    "#     for i in range(len(sim_list)):\n",
    "# #         print(sim_list[i])\n",
    "#         if sim_list[i] == 1.0:\n",
    "#             cnt = cnt+1\n",
    "#     sim_level = ((cnt*1.0)/(len(sim_list)))*100\n",
    "    sim_level = abs(sim_list)*100\n",
    "    #print(\"Node Similarity Percentage = \", sim_level)\n",
    "    return sim_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_correlation_plotter(node1, node2, option=1):\n",
    "    sim, max_val, min_val = cosine_similarity_finder(node1, node2)\n",
    "    if option == 1:\n",
    "        new_sim = np.reshape(sim, (len(sim),1))\n",
    "        #print(len(sim))\n",
    "        intersection_matrix = np.zeros((len(sim), len(sim)))\n",
    "        #print(intersection_matrix)\n",
    "        k=0\n",
    "        for i in range(0, len(intersection_matrix)):\n",
    "            for j in range(0, len(intersection_matrix)):\n",
    "                if i==j:\n",
    "                    intersection_matrix[i][j] = sim[k]\n",
    "                    k = k+1\n",
    "        #print(len(intersection_matrix))\n",
    "        plt.matshow(intersection_matrix, cmap=plt.cm.Blues)\n",
    "        for i in range(0, len(intersection_matrix)):\n",
    "            for j in range(0, len(intersection_matrix)):\n",
    "                c = intersection_matrix[j,i]\n",
    "                plt.text(i, j, str(c), va='center', ha='center')\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tens_1 = torch.tensor([0.5, 0.3, 1.2, 0.33])\n",
    "# tens_2 = torch.tensor([0.3, 0.2, 1.3, 1.4])\n",
    "# # node1 = data.x[0]\n",
    "# # node2 = data.x[633]\n",
    "# sim = node_correlation_plotter(torch.reshape(node1, ((node1.size())[0], 1)), torch.reshape(node2, ((node2.size())[0], 1)), 0)\n",
    "# sim_lev = similarity_percentage(sim)\n",
    "# print(sim_lev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_edge_dictionary(edge_data):\n",
    "    edge_dict={}\n",
    "    for i in range(edge_data.size()[0]):\n",
    "        x = edge_data.tolist()\n",
    "        temp = []\n",
    "        if x[i][0] in edge_dict:\n",
    "            temp = edge_dict[x[i][0]]\n",
    "        temp.append(x[i][1])\n",
    "        edge_dict[x[i][0]] = temp\n",
    "        #print(edge_dict[x[i][0]])\n",
    "    return edge_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE EDGE DICTIONARY\n",
    "# node1 = torch.tensor([1, 2, 3, 4], dtype=torch.float)\n",
    "# print(node1.size())\n",
    "# node2 = torch.tensor([1, 2, 2, 4], dtype=torch.float)\n",
    "# node_correlation_plotter(torch.reshape(node1, ((node1.size())[0], 1)), torch.reshape(node2, ((node2.size())[0], 1)), 0)\n",
    "edge_data = data.edge_index.t()\n",
    "edge_dict = make_edge_dictionary(edge_data)\n",
    "print(edge_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GENERIC FRAMEWORK FOR GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_layers, hidden_channels):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(1234567)\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(GCNConv(dataset.num_features, hidden_channels))\n",
    "        if num_layers > 1:\n",
    "            for i in range(num_layers-2):\n",
    "                self.convs.append(GCNConv(hidden_channels, hidden_channels))\n",
    "            self.convs.append(GCNConv(hidden_channels, 2))\n",
    "            self.classifier = Linear(2, dataset.num_classes)\n",
    "        else:\n",
    "            self.classifier = Linear(hidden_channels, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, num_layers):\n",
    "        h=x\n",
    "        for l in range(num_layers-1):\n",
    "            h = self.convs[l](h, edge_index)\n",
    "            h = h.tanh()\n",
    "#             h = F.dropout(h, p=0.5, training=self.training)\n",
    "#         if num_layers > 1:\n",
    "#             h = torch.nn.functional.relu(h)\n",
    "        h = self.convs[num_layers-1](h, edge_index)\n",
    "        h = h.tanh()\n",
    "#             #h = torch.nn.functional.relu(h)\n",
    "#             #h = F.dropout(h, p=0.5, training=self.training)\n",
    "#             h = self.convs[l](h, edge_index)\n",
    "#             #h = h.tanh()\n",
    "#           else:\n",
    "#             #h = torch.nn.functional.dropout(h, dropout=0.5, training=self.training)\n",
    "#             h = self.convs[l](h, edge_index)\n",
    "#             #h = h.tanh()\n",
    "#             h = h.relu()\n",
    "#             h = F.dropout(h, p=0.5, training=self.training)\n",
    "        out = self.classifier(h)\n",
    "            #x = F.dropout(x, p=0.5, training=self.training)\n",
    "        return out, h\n",
    "\n",
    "model = GCN(3, hidden_channels=4)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Javascript  # Restrict height of output cell.\n",
    "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n",
    "\n",
    "def init_model(num_layers):\n",
    "      model = GCN(num_layers, hidden_channels=16)\n",
    "      optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "      criterion = torch.nn.CrossEntropyLoss()\n",
    "      return model, optimizer, criterion\n",
    "\n",
    "def train(model, optimizer, criterion, num_layers):\n",
    "      model.train()\n",
    "      optimizer.zero_grad()  # Clear gradients.\n",
    "      out, h = model(data.x, data.edge_index, num_layers)  # Perform a single forward pass.\n",
    "      loss = criterion(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n",
    "      loss.backward()  # Derive gradients.\n",
    "      optimizer.step()  # Update parameters based on gradients.\n",
    "      # Calculate training accuracy on our four examples\n",
    "#       predicted_classes = torch.argmax(out[data.train_mask], axis=1) # [0.6, 0.2, 0.7, 0.1] -> 2\n",
    "#       target_classes = data.y[data.train_mask]\n",
    "#       accuracy = torch.mean(torch.where(predicted_classes == target_classes, 1, 0).float())\n",
    "#       predicted_classes = torch.argmax(out, axis=1)\n",
    "#       target_classes = data.y\n",
    "#       accuracy_val = torch.mean(torch.where(predicted_classes == target_classes, 1, 0).float())\n",
    "      accuracy = 0\n",
    "      accuracy_val = 0\n",
    "      return out, h, loss, accuracy, accuracy_val\n",
    "\n",
    "def train_test(model, optimizer, criterion, num_layers):\n",
    "      model.eval()\n",
    "      out, h = model(data.x, data.edge_index, num_layers)\n",
    "      predicted_classes = torch.argmax(out[data.train_mask], axis=1)\n",
    "      target_classes = data.y[data.train_mask]\n",
    "      #train_correct = pred[data.train_mask] == data.y[data.train_mask]  # Check against ground-truth labels.\n",
    "      #print(out)\n",
    "      train_acc = torch.mean(torch.where(predicted_classes == target_classes, 1, 0).float())\n",
    "      predicted_classes = torch.argmax(out, axis=1)\n",
    "      target_classes = data.y\n",
    "      accuracy_val = torch.mean(torch.where(predicted_classes == target_classes, 1, 0).float())\n",
    "      return train_acc, accuracy_val\n",
    "\n",
    "def test(model, optimizer, criterion, num_layers):\n",
    "      model.eval()\n",
    "      out = model(data.x, data.edge_index, num_layers)\n",
    "      pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "      test_correct = pred[data.test_mask] == data.y[data.test_mask]  # Check against ground-truth labels.\n",
    "      test_acc = int(test_correct.sum()) / int(data.test_mask.sum())  # Derive ratio of correct predictions.\n",
    "      return test_acc\n",
    "\n",
    "def call_train(model, optimizer, criterion, num_layers):\n",
    "    for epoch in range(1, 101):\n",
    "        out, h, loss, accuracy, accuracy_val = train(model, optimizer, criterion, num_layers)\n",
    "        if epoch==0 or epoch%100==0:\n",
    "            print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
    "    accuracy, accuracy_val = train_test(model, optimizer, criterion, num_layers)\n",
    "    return out, h, accuracy, accuracy_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeler(num_layers):\n",
    "      model, optimizer, criterion = init_model(num_layers)\n",
    "      out_x, h, accuracy, accuracy_val = call_train(model, optimizer, criterion, num_layers)\n",
    "      #test_acc = test(model, optimizer, criterion, num_layers)*100\n",
    "      #test_accuracy_list.append(test_acc)\n",
    "      #train_acc = train_test(model, optimizer, criterion, num_layers)*100\n",
    "      train_accuracy_list.append(accuracy.item())\n",
    "      val_accuracy_list.append(accuracy_val.item())\n",
    "      #print(f'Test Accuracy: {test_acc:.4f}')\n",
    "      print(f'Train Accuracy: {accuracy:.4f}')\n",
    "      print(f'Val Accuracy: {accuracy_val:.4f}')\n",
    "      return model, out_x, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def node_similarity_simulator(output):\n",
    "#     output_similarity_matrix = []\n",
    "#     output_similarity_percentages = []\n",
    "#     for i in range(output.size()[0]):\n",
    "#         for j in range(output.size()[0]):\n",
    "#             if i in edge_dict and i<j:\n",
    "#                 if edge_dict[i].count(j)>0:\n",
    "#                     sim = node_correlation_plotter(torch.reshape(output[i], ((output[i].size())[0], 1)), torch.reshape(output[j], ((output[j].size())[0], 1)), 0)\n",
    "#                     output_similarity_matrix.append(sim)\n",
    "#                     entry = []\n",
    "#                     entry.append(i)\n",
    "#                     entry.append(j)\n",
    "#                     entry.append(similarity_percentage(sim))\n",
    "#                     output_similarity_percentages.append(entry)\n",
    "#                 else\n",
    "#     return output_similarity_matrix, output_similarity_percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## SKIP NON CONNECTED EDGES\n",
    "# def node_similarity_simulator(output):\n",
    "#     output_similarity_matrix = []\n",
    "#     output_similarity_matrix_plot = []\n",
    "#     output_similarity_percentages = []\n",
    "#     print(output.size()[0])\n",
    "#     for i in range(output.size()[0]):\n",
    "#         temper = []\n",
    "#         for j in range(output.size()[0]):\n",
    "#             if i in edge_dict and edge_dict[i].count(j)>0:\n",
    "#                 sim = node_correlation_plotter(output[i], output[j], 0)\n",
    "#                 output_similarity_matrix.append(sim)\n",
    "#                 temper.append(round(float(sim),2))\n",
    "#                 entry = []\n",
    "#                 entry.append(i)\n",
    "#                 entry.append(j)\n",
    "#                 entry.append(similarity_percentage(sim))\n",
    "#                 output_similarity_percentages.append(entry)\n",
    "#             else:\n",
    "#                 output_similarity_matrix.append(0.0)\n",
    "#                 temper.append(0.0)\n",
    "#         output_similarity_matrix_plot.append(temper)\n",
    "#     return output_similarity_matrix, output_similarity_percentages, output_similarity_matrix_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CONSIDER NON CONNECTED EDGES\n",
    "def node_similarity_simulator(output):\n",
    "    output_similarity_matrix = []\n",
    "    output_similarity_matrix_plot = []\n",
    "    output_similarity_percentages = []\n",
    "    print(output.size()[0])\n",
    "    for i in range(output.size()[0]):\n",
    "        temper = []\n",
    "        for j in range(output.size()[0]):\n",
    "            #sim = node_correlation_plotter(torch.reshape(output[i], ((output[i].size())[0], 1)), torch.reshape(output[j], ((output[j].size())[0], 1)), 0)\n",
    "            sim = node_correlation_plotter(output[i], output[j], 0)\n",
    "            output_similarity_matrix.append(sim)\n",
    "            #print(sim)\n",
    "            temper.append(round(float(sim),4))\n",
    "            entry = []\n",
    "            entry.append(i)\n",
    "            entry.append(j)\n",
    "            entry.append(similarity_percentage(sim))\n",
    "            output_similarity_percentages.append(entry)\n",
    "        output_similarity_matrix_plot.append(temper)\n",
    "    return output_similarity_matrix, output_similarity_percentages, output_similarity_matrix_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one(x):\n",
    "    if x>0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_DTGT(output_similarity_matrix, M, DTGT):\n",
    "    ans = torch.mul(torch.tensor(output_similarity_matrix), torch.tensor(M))\n",
    "    l = len(output_similarity_matrix)\n",
    "    for i in range(l):\n",
    "        temp = ans[i]\n",
    "        temp_sum = torch.sum(temp)\n",
    "        x = []\n",
    "        for j in range(temp.size()[0]):\n",
    "            x.append(get_one(temp[j]))\n",
    "        x_sum = torch.sum(torch.tensor(x), 0)\n",
    "        DTGT[i] = ((temp_sum)/x_sum).item()\n",
    "    return DTGT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mad_calc(DTGT):\n",
    "    temp = DTGT\n",
    "    #print(temp.tolist())\n",
    "    temp_sum = torch.sum(torch.tensor(DTGT))\n",
    "    #print(temp_sum)\n",
    "    x = []\n",
    "    for j in range(len(temp)):\n",
    "        x.append(get_one(temp[j]))\n",
    "    x_sum = torch.sum(torch.tensor(x), 0)\n",
    "    MAD = (temp_sum)/x_sum\n",
    "    #print(MAD)\n",
    "    return MAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_MAD(output_similarity_matrix, output_similarity_percentages):\n",
    "    l = len(output_similarity_matrix)\n",
    "    M = np.zeros((l, l))\n",
    "    DTGT = np.zeros((l, 1))\n",
    "    for i in range(l):\n",
    "        for j in range(l):\n",
    "            M[i][j]=1.0\n",
    "    DTGT = get_DTGT(output_similarity_matrix, M, DTGT)\n",
    "    where_are_NaNs = np.isnan(DTGT)\n",
    "    DTGT[where_are_NaNs] = 0\n",
    "    MAD = mad_calc(DTGT)\n",
    "    return MAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numpy import mean, absolute\n",
    "# def mad(data, axis=None):\n",
    "#     return mean(absolute(data - mean(data, axis)), axis)\n",
    "\n",
    "# def mad_calc(output_similarity_matrix, output_similarity_percentages):\n",
    "#     l = len(output_similarity_matrix)\n",
    "#     for i in range(len(output_similarity_matrix)):\n",
    "#         temp = output_similarity_matrix[i]\n",
    "#         mad_temp = mad(temp)\n",
    "#         print(mad_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## WITHOUT MAD\n",
    "# test_accuracy_list = []\n",
    "# train_accuracy_list = []\n",
    "# xpoints = []\n",
    "# MAD_SCORES = []\n",
    "# def layer_modeler(m):\n",
    "#     for i in range(m, m+1):\n",
    "#         print(\"######### LAYER = \", i, \" #######\")\n",
    "#         xpoints.append(i)\n",
    "#         model = modeler(i)\n",
    "#         #if i==m:\n",
    "#         model.eval()\n",
    "#         output = model(data.x, data.edge_index, i)\n",
    "#         output_similarity_matrix, output_similarity_percentages, output_similarity_matrix_plot = node_similarity_simulator(output)\n",
    "#         #print(output_similarity_matrix)\n",
    "#             #visualize(output, color=data.y)\n",
    "#         print(model)\n",
    "# #         mad_calc(output_similarity_matrix, output_similarity_percentages)\n",
    "# #         mad_score = find_MAD(output_similarity_matrix, output_similarity_percentages)\n",
    "# #         MAD_SCORES.append(mad_score.item())\n",
    "#         return output_similarity_matrix, output_similarity_percentages, output_similarity_matrix_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cosine_distance_matrix(output_similarity_matrix_plot):\n",
    "    cosine_diff_matrix = []\n",
    "    for i in range(len(output_similarity_matrix_plot)):\n",
    "        temp = []\n",
    "        for j in range(len(output_similarity_matrix_plot)):\n",
    "            temp.append((1-output_similarity_matrix_plot[i][j]))\n",
    "        cosine_diff_matrix.append(temp)\n",
    "    return cosine_diff_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def euc_dist(tensor1, tensor2):\n",
    "    dist = torch.dist(tensor1, tensor2, 2) \n",
    "    return dist.item()\n",
    "def get_row_diff(node_array, N):\n",
    "    eud_dist_mat = []\n",
    "    for i in range(len(node_array)):\n",
    "        temp = []\n",
    "        for j in range(len(node_array)):\n",
    "            if i!=j:\n",
    "                eud = euc_dist(torch.tensor(node_array[i]), torch.tensor(node_array[j]))\n",
    "                temp.append(eud)\n",
    "        row_sum_node = torch.sum(torch.tensor(temp))\n",
    "        row_sum_avg = row_sum_node/(N-1)\n",
    "        eud_dist_mat.append(row_sum_avg)\n",
    "    return eud_dist_mat\n",
    "def row_diff_finder(node_array, N):\n",
    "    row_diff = get_row_diff(node_array, N)\n",
    "    row_diff_sum = torch.sum(torch.tensor(row_diff))\n",
    "    differ = row_diff_sum/(N)\n",
    "    return differ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "def similarity_aggregation(sim_matrix):\n",
    "    avg_sim = statistics.mean(sim_matrix)\n",
    "    return avg_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WITH MAD\n",
    "test_accuracy_list = []\n",
    "train_accuracy_list = []\n",
    "val_accuracy_list = []\n",
    "avg_sim_list = []\n",
    "xpoints = []\n",
    "MAD_SCORES = []\n",
    "def layer_modeler(m):\n",
    "    for i in range(m, m+1):\n",
    "        print(\"######### LAYER = \", i, \" #######\")\n",
    "        xpoints.append(i)\n",
    "        model, out_x, h = modeler(i)\n",
    "#         model.eval()\n",
    "#         output = model(data.x, data.edge_index, i)\n",
    "        #transformation(h)\n",
    "        output_similarity_matrix, output_similarity_percentages, output_similarity_matrix_plot = node_similarity_simulator(h)\n",
    "        print(model)\n",
    "        avg_sim = similarity_aggregation(output_similarity_matrix)\n",
    "        avg_sim_list.append(avg_sim)\n",
    "        cosine_diff_matrix = find_cosine_distance_matrix(output_similarity_matrix_plot)\n",
    "        mad_score = find_MAD(cosine_diff_matrix, output_similarity_percentages)\n",
    "        MAD_SCORES.append(mad_score.item())\n",
    "        #print(output)\n",
    "        row_diff = row_diff_finder(h.tolist(), len(output_similarity_matrix_plot))\n",
    "        #if i==m:\n",
    "            #visualize(h, color=data.y)\n",
    "        return output_similarity_matrix, output_similarity_percentages, output_similarity_matrix_plot, row_diff, cosine_diff_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrival(m):\n",
    "    sim_mat = []\n",
    "    row_diff_mat = []\n",
    "    diff_mat = []\n",
    "    for i in range(2, m+1):\n",
    "        output_similarity_matrix, output_similarity_percentages, output_similarity_matrix_plot, row_diff, cosine_diff_matrix = layer_modeler(i)\n",
    "        #print(output_similarity_matrix_plot)\n",
    "        sim_mat.append(output_similarity_matrix_plot)\n",
    "        print(np.asarray(output_similarity_matrix_plot).shape)\n",
    "        row_diff_mat.append(row_diff)\n",
    "        diff_mat.append(cosine_diff_matrix)\n",
    "    return sim_mat, row_diff_mat, diff_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gotcha(m, rows, cols, sim):\n",
    "    row=0\n",
    "    col = 0\n",
    "    fig, ax = plt.subplots(rows, cols,\n",
    "                       sharex='col', \n",
    "                       sharey='row', figsize=(10,5))\n",
    "    for i in range(0, len(sim)):\n",
    "        if col <3:\n",
    "            ax[row, col].matshow(sim[i], cmap=plt.cm.Blues)\n",
    "            st = \"Depth = \"+str(i+1)\n",
    "            ax[row, col].title.set_text(st)\n",
    "            col = col + 1\n",
    "        else:\n",
    "            row = row + 1\n",
    "            col = 0\n",
    "            ax[row, col].matshow(sim[i], cmap=plt.cm.Blues)\n",
    "            st = \"Depth = \"+str(i+1)\n",
    "            ax[row, col].title.set_text(st)\n",
    "            col = col + 1\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_scores, row_differences, difference_scores = arrival(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "m = 7\n",
    "gotcha(m, 3, 3, similarity_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "# m = 7\n",
    "# gotcha(m, 2, 3, difference_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(avg_sim_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MAD_SCORES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_accuracy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(val_accuracy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = [train_accuracy_list, val_accuracy_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def euc_dist(tensor1, tensor2):\n",
    "#     dist = torch.dist(tensor1, tensor1, 2) \n",
    "#     return dist.item()\n",
    "# def get_row_diff(node_array):\n",
    "#     eud_dist_mat = []\n",
    "#     for i in range(len(node_array)):\n",
    "#         temp = []\n",
    "#         for j in range(len(node_array)):\n",
    "#             #print(node_array[j])\n",
    "#             eud = euc_dist(torch.tensor(node_array[i]), torch.tensor(node_array[j]))\n",
    "#             temp.append(eud)\n",
    "#         eud_dist_mat.append(temp)\n",
    "#     return eud_dist_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datax = data.x.tolist()\n",
    "# row_diff = get_row_diff(datax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "xpoints = np.array(xpoints)\n",
    "ypoints = np.array(train_accuracy_list)\n",
    "plt.xlabel(\"Depth\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.plot(xpoints, ypoints, 'ob-')\n",
    "for x,y in zip(xpoints,ypoints):\n",
    "\n",
    "    label = \"{:.2f}\".format(y)\n",
    "\n",
    "    plt.annotate(label, # this is the text\n",
    "                 (x,y), # these are the coordinates to position the label\n",
    "                 textcoords=\"offset points\", # how to position the text\n",
    "                 xytext=(0,10), # distance from text to points (x,y)\n",
    "                 ha='center') # horizontal alignment can be left, right or center\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "xpoints = np.array(xpoints)\n",
    "ypoints = np.array(val_accuracy_list)\n",
    "plt.xlabel(\"Depth\")\n",
    "plt.ylabel(\"Val Accuracy\")\n",
    "plt.plot(xpoints, ypoints, 'ob-')\n",
    "for x,y in zip(xpoints,ypoints):\n",
    "\n",
    "    label = \"{:.2f}\".format(y)\n",
    "\n",
    "    plt.annotate(label, # this is the text\n",
    "                 (x,y), # these are the coordinates to position the label\n",
    "                 textcoords=\"offset points\", # how to position the text\n",
    "                 xytext=(0,10), # distance from text to points (x,y)\n",
    "                 ha='center') # horizontal alignment can be left, right or center\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({\"Training\": train_accuracy_list,\n",
    "                 \"Validation\" : val_accuracy_list})\n",
    "p = sns.lineplot(data = df)\n",
    "p.set( xlabel = \"Layers\", ylabel = \"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({\"Training\": train_accuracy_list,\n",
    "                 \"Validation\" : val_accuracy_list})\n",
    "p = sns.lineplot(data = df)\n",
    "p.set( xlabel = \"Layers\", ylabel = \"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(output_similarity_percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(output_similarity_percentages)):\n",
    "#         print(\"Node i = \" , output_similarity_percentages[i][0], \", Node j = \", output_similarity_percentages[i][1], \" Similarity Percentage = \", output_similarity_percentages[i][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(output_similarity_matrix)\n",
    "# print(len(output_similarity_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(output_similarity_matrix_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.asarray(output_similarity_matrix_plot).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def similarity_plotter(output_similarity_matrix_plot):\n",
    "# #     intersection_matrix = np.zeros((len(output_similarity_matrix_plot), len(output_similarity_matrix_plot)))\n",
    "# #     for i in range(0, len(output_similarity_matrix_plot)):\n",
    "# #         for j in range(0, len(output_similarity_matrix_plot[i])):\n",
    "# #             intersection_matrix[i][j]= output_similarity_matrix_plot[i][j][0]\n",
    "#     plt.matshow(output_similarity_matrix_plot, cmap=plt.cm.Blues)\n",
    "# #     for i in range(0, len(output_similarity_matrix_plot)):\n",
    "# #         for j in range(0, len(output_similarity_matrix_plot)):\n",
    "# #             c = output_similarity_matrix_plot[i][j]\n",
    "# #             plt.text(i, j, str(c), va='center', ha='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity_plotter(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def gotcha(m):\n",
    "#     rows, cols = 3, 3\n",
    "#     sim = arrival(m)\n",
    "#     row=0\n",
    "#     col = 0\n",
    "#     fig, ax = plt.subplots(rows, cols,\n",
    "#                        sharex='col', \n",
    "#                        sharey='row', figsize=(10,5))\n",
    "#     for i in range(0, len(sim)):\n",
    "#         if col <3:\n",
    "#             ax[row, col].matshow(sim[i], cmap=plt.cm.Blues)\n",
    "#             st = \"Depth = \"+str(i+2)\n",
    "#             ax[row, col].title.set_text(st)\n",
    "#             col = col + 1\n",
    "#         else:\n",
    "#             row = row + 1\n",
    "#             col = 0\n",
    "#             ax[row, col].matshow(sim[i], cmap=plt.cm.Blues)\n",
    "#             st = \"Depth = \"+str(i+2)\n",
    "#             ax[row, col].title.set_text(st)\n",
    "#             col = col + 1\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gotcha(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# fig, ax = plt.subplots(rows, cols,\n",
    "#                        sharex='col', \n",
    "#                        sharey='row')\n",
    "\n",
    "# for row in range(rows):\n",
    "#     for col in range(cols):\n",
    "#         ax[row, col].text(0.5, 0.5, \n",
    "#                           str((row, col)),\n",
    "#                           color=\"green\",\n",
    "#                           fontsize=18, \n",
    "#                           ha='center')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def group_by_node():\n",
    "#     node_group={}\n",
    "#     for i in range(len(output_similarity_percentages)):\n",
    "#         temp = []\n",
    "#         if output_similarity_percentages[i][0] in node_group:\n",
    "#             temp = node_group[output_similarity_percentages[i][0]]\n",
    "#         temp.append(output_similarity_percentages[i][2])\n",
    "#         node_group[output_similarity_percentages[i][0]] = temp\n",
    "#     return node_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# node_grouping = group_by_node()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# node_grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statistics\n",
    "# def aggr_by_node():\n",
    "#     node_aggr={}\n",
    "#     for i in range(len(output_similarity_percentages)):\n",
    "#         temp = []\n",
    "#         if output_similarity_percentages[i][0] in node_grouping:\n",
    "#             temp = node_grouping[output_similarity_percentages[i][0]]\n",
    "#         node_aggr[output_similarity_percentages[i][0]] = statistics.mean(temp)\n",
    "#     return node_aggr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggr = aggr_by_node()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_aggr = list(aggr.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_aggr = statistics.mean(list_aggr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_aggr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l = len(output_similarity_matrix)\n",
    "# M = np.zeros((l, l))\n",
    "# DTGT = np.zeros((l, 1))\n",
    "# for i in range(l):\n",
    "#     for j in range(l):\n",
    "#         M[i][j]=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_one(x):\n",
    "#     if x>0:\n",
    "#         return 1\n",
    "#     else:\n",
    "#         return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ans = torch.mul(torch.tensor(output_similarity_matrix), torch.tensor(M))\n",
    "# #print(ans)\n",
    "# for i in range(l):\n",
    "#     temp = ans[i]\n",
    "#     temp_sum = torch.sum(temp)\n",
    "#     x = []\n",
    "#     for j in range(temp.size()[0]):\n",
    "#         x.append(get_one(temp[j]))\n",
    "#     x_sum = torch.sum(torch.tensor(x))\n",
    "#     DTGT[i] = ((temp_sum*1.0)/x_sum).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where_are_NaNs = np.isnan(DTGT)\n",
    "# DTGT[where_are_NaNs] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = DTGT\n",
    "# temp_sum = torch.sum(torch.tensor(temp))\n",
    "# x = []\n",
    "# for j in range(len(temp)):\n",
    "#     x.append(get_one(temp[j]))\n",
    "# x_sum = torch.sum(torch.tensor(x))\n",
    "# MAD = (temp_sum*1.0)/x_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(MAD.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of 2. Node Classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
